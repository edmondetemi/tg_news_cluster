{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from collections import Counter\n",
    "import math\n",
    "import re\n",
    "import json\n",
    "import subprocess\n",
    "import shutil\n",
    "import pickle\n",
    "import multiprocessing\n",
    "import itertools\n",
    "import random\n",
    "import time\n",
    "\n",
    "import requests\n",
    "from requests import Request, Session\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "import pandas as pd\n",
    "import umap\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris, load_digits\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import language\n",
    "import text_nn\n",
    "import grab_category\n",
    "import news\n",
    "import groups\n",
    "import libs.cpp_stuff as cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_info = language.read_dump(\"data/website/en/all\")\n",
    "file_info.extend(language.read_dump(\"data/website/ru/all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feeder_script(file_info, num_streams, script_file):\n",
    "    stream_commands = [[] for _ in range(num_streams)]\n",
    "    for i in range(0, len(file_info), num_streams):\n",
    "        for s in range(num_streams):\n",
    "            n = i + s\n",
    "            if n >= len(file_info):\n",
    "                break\n",
    "\n",
    "            stream_commands[s].append(f\"curl -X PUT 127.0.0.1:1111/{os.path.basename(file_info[n].file)} --data-binary @{file_info[n].file} \"\n",
    "                                      f\"-H 'Cache-Control: max-age=10000000'\")\n",
    "            \n",
    "    script = \"\\n\".join(\" ( \" + \" ; \".join(s) + \" ) &\" for s in stream_commands) + \"\\nwait\\n\"\n",
    "    with open(script_file, \"w\") as f:\n",
    "        f.write(script)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_feeder_script(file_info, 30, \"feed_both.sh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_info = language.read_dump(\"data/sample6/all\")\n",
    "make_feeder_script(file_info, 30, \"feed6.sh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dump = \"data/website/en/all_dump\"\n",
    "if not os.path.exists(all_dump):\n",
    "    os.mkdir(all_dump)\n",
    "    \n",
    "for fi in file_info:\n",
    "    dest = os.path.join(all_dump, os.path.basename(fi.file))\n",
    "    if not os.path.exists(dest):\n",
    "        os.symlink(os.path.abspath(fi.file), dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "s = Session()\n",
    "url = \"http://127.0.0.1:1111/threads?period=4353000&lang_code=en&category=society\"\n",
    "req = Request('GET', url)\n",
    "\n",
    "prepped = s.prepare_request(req)\n",
    "\n",
    "# do something with prepped.body\n",
    "#prepped.body = 'Seriously, send exactly these bytes.'\n",
    "\n",
    "# do something with prepped.headers\n",
    "#prepped.headers['Keep-Dead'] = 'parrot'\n",
    "\n",
    "resp = s.send(prepped)\n",
    "\n",
    "print(resp.status_code)\n",
    "json.loads(resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "retry = Retry(connect=3, backoff_factor=0.5)\n",
    "adapter = HTTPAdapter(max_retries=retry)\n",
    "session.mount('http://', adapter)\n",
    "\n",
    "def get_articles(language):\n",
    "    resp = session.get(f\"http://127.0.0.1:1111/threads?period=4353000&lang_code={language}&category=any\")\n",
    "    assert resp.status_code == 200\n",
    "    res = json.loads(resp.content)[\"threads\"]\n",
    "    articles = set()\n",
    "    for t in res:\n",
    "        assert not any(a in articles for a in t[\"articles\"])\n",
    "        articles.update(t[\"articles\"])\n",
    "        \n",
    "    return articles\n",
    "\n",
    "def get_all_articles():\n",
    "    en = get_articles(\"en\")\n",
    "    ru = get_articles(\"ru\")\n",
    "    assert en.isdisjoint(ru)\n",
    "    return en | ru\n",
    "\n",
    "def put_article(article_id, body, max_age):\n",
    "    resp = session.put(f\"http://127.0.0.1:1111/{article_id}\", data=body, headers={'Cache-Control': f'max-age={max_age}'})\n",
    "    assert resp.status_code == 201 or resp.status_code == 204\n",
    "    return resp.status_code == 201\n",
    "\n",
    "def put_article_data(fi, max_age):\n",
    "    article_id = os.path.basename(fi.file)\n",
    "\n",
    "    with open(fi.file, \"rb\") as f:\n",
    "        body = f.read()\n",
    "        \n",
    "    return \"put\", (article_id, body, max_age)\n",
    "\n",
    "def del_article(article_id):\n",
    "    resp = session.delete(f\"http://127.0.0.1:1111/{article_id}\")\n",
    "    assert resp.status_code == 404 or resp.status_code == 204\n",
    "    return resp.status_code == 204\n",
    "\n",
    "def del_article_data(fi):\n",
    "    return \"del\", os.path.basename(fi.file)\n",
    "\n",
    "def req(req_data):\n",
    "    if req_data[0] == \"put\":\n",
    "        return put_article(*req_data[1])\n",
    "    elif req_data[0] == \"del\":\n",
    "        return del_article(req_data[1])\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe29244cbb65404aba12b8e6a1b6e7ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=70330.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "70323 articles in bd\n"
     ]
    }
   ],
   "source": [
    "put_datas = [put_article_data(fi, 1000000000) for fi in tqdm(file_info)]\n",
    "random.shuffle(put_datas)\n",
    "put_datas = [v for v in {pd[1][0]: pd for pd in put_datas}.values()]\n",
    "del_datas = [(\"del\", pd[1][0]) for pd in put_datas]\n",
    "print(len(put_datas), \"articles in bd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = multiprocessing.Pool(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_run(to_run, num):\n",
    "    start_time = time.time()\n",
    "    res = to_run()\n",
    "    spent_time = time.time() - start_time\n",
    "    print(f\"{spent_time / num * 1000:.2f} seconds per 1000 files\")\n",
    "    return res\n",
    "\n",
    "def run_and_check_results(reqs, expected_res):\n",
    "    assert len(reqs) == len(expected_res)\n",
    "    res = time_run(lambda: pool.map(req, reqs), len(reqs))\n",
    "    assert all(r == e for r, e in zip(res, expected_res))\n",
    "    \n",
    "def mix_putdel(put_datas, del_datas, num_cycles, cycle_size, all_accepted):\n",
    "    n = len(put_datas)\n",
    "    full_set = set(range(n))\n",
    "    files_in = set()\n",
    "    art_ids = [dd[1] for dd in del_datas]\n",
    "    for stage in trange(num_cycles):\n",
    "        put_files = np.random.choice(n, cycle_size, replace=False)\n",
    "        put_res = [f not in files_in for f in put_files]\n",
    "        put_req = [put_datas[i] for i in put_files]\n",
    "        del_files = np.random.choice(list(full_set - set(put_files)), cycle_size, replace=False)\n",
    "        del_res = [f in files_in for f in del_files]\n",
    "        del_req = [del_datas[i] for i in del_files]\n",
    "        all_res = put_res + del_res\n",
    "        all_req = put_req + del_req\n",
    "        all_info = list(zip(all_res, all_req))\n",
    "        random.shuffle(all_info)\n",
    "        all_res, all_req = zip(*all_info)\n",
    "        run_and_check_results(all_req, all_res)\n",
    "        files_in.update(put_files)\n",
    "        files_in.difference_update(del_files)\n",
    "        \n",
    "        arts_in = get_all_articles()\n",
    "        should_be_in = set(art_ids[i] for i in files_in)\n",
    "        assert arts_in.issubset(should_be_in), f\"{len(arts_in)} {len(should_be_in)}\"\n",
    "        \n",
    "        if all_accepted is not None:\n",
    "            should_be_accepted = all_accepted & should_be_in\n",
    "            assert arts_in == should_be_accepted\n",
    "        \n",
    "    del_res = [True] * len(files_in)\n",
    "    del_req = [del_datas[i] for i in files_in]\n",
    "    run_and_check_results(del_req, del_res)\n",
    "    \n",
    "    assert not get_all_articles()\n",
    "\n",
    "def add_repeatedly(put_datas, num_times):\n",
    "    res = time_run(lambda: pool.map(req, put_datas), len(put_datas))\n",
    "    assert all(res)\n",
    "    \n",
    "    for _ in range(num_times - 1):\n",
    "        res = time_run(lambda: pool.map(req, put_datas), len(put_datas))\n",
    "        assert not any(res)        \n",
    "    \n",
    "\n",
    "def add_twice_delete_twice(put_datas, del_datas):\n",
    "    assert len(put_datas) == len(del_datas)\n",
    "    add_repeatedly(put_datas, 2)\n",
    "    \n",
    "    res = time_run(lambda: pool.map(req, del_datas), len(put_datas))\n",
    "    assert all(res)\n",
    "\n",
    "    res = time_run(lambda: pool.map(req, del_datas), len(put_datas))\n",
    "    assert not any(res)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_repeatedly(put_datas, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.55 seconds per 1000 files\n",
      "4.40 seconds per 1000 files\n",
      "0.86 seconds per 1000 files\n",
      "0.21 seconds per 1000 files\n"
     ]
    }
   ],
   "source": [
    "add_twice_delete_twice(put_datas, del_datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pool.map(req, del_datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pool.map(req, put_datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35875"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_accepted = get_all_articles()\n",
    "len(all_accepted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c77024a6f64231b02900100e0bc67e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.21 seconds per 1000 files\n",
      "1.24 seconds per 1000 files\n",
      "1.27 seconds per 1000 files\n",
      "1.35 seconds per 1000 files\n",
      "1.36 seconds per 1000 files\n",
      "1.44 seconds per 1000 files\n",
      "1.53 seconds per 1000 files\n",
      "1.66 seconds per 1000 files\n",
      "1.79 seconds per 1000 files\n",
      "1.88 seconds per 1000 files\n",
      "\n",
      "0.86 seconds per 1000 files\n"
     ]
    }
   ],
   "source": [
    "mix_putdel(put_datas, del_datas, 10, 10000, all_accepted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
