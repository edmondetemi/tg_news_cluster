{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from collections import Counter\n",
    "import math\n",
    "import re\n",
    "import json\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import umap\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris, load_digits\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, f1_score\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#assert gpus\n",
    "try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "layers = keras.layers\n",
    "models = keras.models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy.random as rng\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import convert_model\n",
    "\n",
    "import language\n",
    "import text_nn\n",
    "import grab_category\n",
    "import news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199344 train examples, 36394 test\n"
     ]
    }
   ],
   "source": [
    "folders_train = [\"data/sample\", \"data/sample3\", \"data/sample4\"]\n",
    "folder_test = \"data/sample2\"\n",
    "\n",
    "file_info_train = []\n",
    "for folder in folders_train:\n",
    "    file_info_train.extend(language.read_dump(os.path.join(folder, \"langs\", \"dump\", \"en\")))\n",
    "\n",
    "file_info_test = language.read_dump(os.path.join(folder_test, \"langs\", \"dump\", \"en\"))\n",
    "print(f\"{len(file_info_train)} train examples, {len(file_info_test)} test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"society\", \"economy\", \"sports\", \"science\", \"other\", \"technology\", \"entertainment\", \"junk\"]\n",
    "\n",
    "def load_cats(folder):\n",
    "    return {fi.file: cat for cat in categories for fi in language.read_dump(os.path.join(folder, \"categories_en\", \"dump\", cat))}\n",
    "    \n",
    "\n",
    "cats_train = {}\n",
    "for folder in folders_train:\n",
    "    cats_train.update(load_cats(folder))\n",
    "    \n",
    "cats_test = load_cats(folder_test)\n",
    "            \n",
    "assert len(cats_train) == len(file_info_train)\n",
    "assert len(cats_test) == len(file_info_test)\n",
    "\n",
    "def linear_cats(cats, file_info):\n",
    "    res = [\"unknown\"] * len(file_info)\n",
    "    for i, fi in enumerate(file_info):\n",
    "        res[i] = cats[fi.file]\n",
    "    \n",
    "    assert \"unknown\" not in res\n",
    "    return res\n",
    "\n",
    "cats_train = linear_cats(cats_train, file_info_train)\n",
    "cats_test = linear_cats(cats_test, file_info_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 GT examples loaded: 0 junk, 0 category mismatches\n",
      "0 GT groups, 0 non-matching\n"
     ]
    }
   ],
   "source": [
    "file_to_idx = {fi.file: i for i, fi in enumerate(file_info_test)}\n",
    "\n",
    "manual_ground_truth = {}\n",
    "gt_junk = 0\n",
    "gt_cat_mismatch = 0\n",
    "if os.path.exists(os.path.join(folder_test, \"gt_groups_en\")):\n",
    "    with open(os.path.join(folder_test, \"gt_groups_en\")) as f:\n",
    "        for line in f:\n",
    "            idx1, idx2, match = line.strip().split(\"\\t\")\n",
    "            idx1 = file_to_idx[idx1]\n",
    "            idx2 = file_to_idx[idx2]\n",
    "            if cats_test[idx1] == \"junk\" or cats_test[idx2] == \"junk\":\n",
    "                gt_junk += 1\n",
    "                continue\n",
    "                \n",
    "            if cats_test[idx1] != cats_test[idx2]:\n",
    "                gt_cat_mismatch += 1\n",
    "                continue\n",
    "                \n",
    "            match = match == \"True\"\n",
    "            manual_ground_truth[(idx1, idx2)] = match\n",
    "            manual_ground_truth[(idx2, idx1)] = match\n",
    "            \n",
    "def get_gt_groups(gt):\n",
    "    idx_group = {idx1: {idx1} for idx1, _ in gt.keys()}\n",
    "    not_matching = set()\n",
    "    for (idx1, idx2), match in gt.items():\n",
    "        if match:\n",
    "            if idx_group[idx1] is not idx_group[idx2]:\n",
    "                idx_group[idx1].update(idx_group[idx2])\n",
    "                for ii in idx_group[idx2]:\n",
    "                    idx_group[ii] = idx_group[idx1]\n",
    "        else:\n",
    "            not_matching.add((idx1, idx2))\n",
    "    \n",
    "    for idx1, idx2 in not_matching:\n",
    "        assert idx2 not in idx_group[idx1], f\"{idx1} and {idx2} are both matching and non-matching in GT. Group: {idx_group[idx1]}\"\n",
    "        \n",
    "    return idx_group, not_matching\n",
    "        \n",
    "print(f\"{len(manual_ground_truth) // 2} GT examples loaded: {gt_junk} junk, {gt_cat_mismatch} category mismatches\")\n",
    "gt_groups = get_gt_groups(manual_ground_truth)\n",
    "print(f\"{len(gt_groups[0])} GT groups, {len(gt_groups[1])} non-matching\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_input = [f\"{len(file_info_train)}\"]\n",
    "for fi in file_info_train:\n",
    "    count_input.append(\" \".join(token for token in news.simple_tokenize_with_numbers(fi.text)))\n",
    "\n",
    "language.run_process([\"groups/Release/news_groups\", \"count\", \"data/chunk_counts_en.bin\"], \"\\n\".join(count_input) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_similarities(texts, similarity_cutoff):\n",
    "    p = subprocess.Popen([\"groups/Release/news_groups\", \"group\", \"data/chunk_counts_en.bin\", str(similarity_cutoff)], stdin=subprocess.PIPE, stdout=subprocess.PIPE,\n",
    "                         encoding=\"utf8\", text=True)\n",
    "    \n",
    "    process_input = f\"{len(texts)}\\n\"\n",
    "    for text in texts:\n",
    "        process_input += text + \"\\n\"\n",
    "\n",
    "    output, _ = p.communicate(process_input)\n",
    "\n",
    "    similarities = [[y.split(\" \") for y in x.strip().split(\"\\t\") if y != \"\"] for x in output[:-1].split(\"\\n\")]           \n",
    "    similarities = [[(int(idx), float(sim)) for idx, sim in sims] for sims in similarities]\n",
    "    return similarities\n",
    "\n",
    "def calc_similarities_within_categories(texts, similarity_cutoff, cats):\n",
    "    all_cats = frozenset(cats) - frozenset([\"junk\"])\n",
    "    res = []\n",
    "    for cat in all_cats:\n",
    "        idx = [i for i, c in enumerate(cats) if c == cat]\n",
    "        cat_sims = calc_similarities([texts[i] for i in idx], similarity_cutoff)\n",
    "        res.extend([[(idx[idx2], sim) for idx2, sim in sims] for sims in cat_sims])\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_groups(texts, similarity_cutoff):\n",
    "    process_input = \"\\n\".join([f\"{len(texts)}\"] + texts) + \"\\n\"\n",
    "    output = language.run_process([\"groups/Release/news_groups\", \"group\", \"data/chunk_counts_en.bin\", str(similarity_cutoff)], process_input)\n",
    "    groups = [[int(y) for y in x.strip().split(\"\\t\") if y != \"\"] for x in output[:-1].split(\"\\n\")]           \n",
    "    return groups\n",
    "\n",
    "def calc_groups_within_categories(texts, similarity_cutoff, cats):\n",
    "    all_cats = frozenset(cats) - frozenset([\"junk\"])\n",
    "    res = []\n",
    "    for cat in all_cats:\n",
    "        idx = [i for i, c in enumerate(cats) if c == cat]\n",
    "        cat_groups = calc_groups([texts[i] for i in idx], similarity_cutoff)\n",
    "        res.extend([[idx[i] for i in group] for group in cat_groups])\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx_group(groups):\n",
    "    idx_group = {}\n",
    "    for group in groups:\n",
    "        for idx in group:\n",
    "            idx_group[idx] = group\n",
    "            \n",
    "    return idx_group\n",
    "\n",
    "def group_comparison(gt_groups, test_groups):\n",
    "    gt_idx_group, gt_not_matching = gt_groups\n",
    "    test_idx_group = idx_group(test_groups)\n",
    "    true_assignments = []\n",
    "    test_assignments = []\n",
    "    for idx1, others in gt_idx_group.items():\n",
    "        for idx2 in others:\n",
    "            if idx1 < idx2:\n",
    "                true_assignments.append(True)                \n",
    "                test_assignments.append(idx1 in test_idx_group and idx2 in test_idx_group[idx1])\n",
    "    \n",
    "    for idx1, idx2 in gt_not_matching:\n",
    "        true_assignments.append(False)\n",
    "        test_assignments.append(not (idx1 in test_idx_group and idx2 in test_idx_group[idx1]))\n",
    "        \n",
    "    return true_assignments, test_assignments\n",
    "\n",
    "def group_to_embedding_comparison(gt_groups, embs):\n",
    "    gt_idx_group, gt_not_matching = gt_groups\n",
    "    true_assignments = []\n",
    "    test_assignments = []\n",
    "    for idx1, others in gt_idx_group.items():\n",
    "        for idx2 in others:\n",
    "            if idx1 < idx2:\n",
    "                true_assignments.append(0)                \n",
    "                test_assignments.append(((embs[idx1, :] - embs[idx2, :]) ** 2).sum())\n",
    "    \n",
    "    for idx1, idx2 in gt_not_matching:\n",
    "        true_assignments.append(1)\n",
    "        test_assignments.append(((embs[idx1, :] - embs[idx2, :]) ** 2).sum())\n",
    "        \n",
    "    return true_assignments, test_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "def calc_groups_within_categories_fi(file_info):    \n",
    "    texts = [\" \".join(token for token in news.simple_tokenize_with_numbers(fi.text)[:500]) for fi in file_info]\n",
    "    return calc_groups_within_categories(texts, 3.5, cats_test)\n",
    "\n",
    "\n",
    "#train_groups = calc_groups_within_categories_fi(file_info_train)\n",
    "test_groups = calc_groups_within_categories_fi(file_info_test)\n",
    "print(f1_score(*group_comparison(gt_groups, test_groups), average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/grouping_output.txt\", \"w\") as f:\n",
    "    for group in sorted(test_groups, key=lambda x: len(x), reverse=True):\n",
    "        f.write(f\"GROUP SIZE: {len(group)}\\n\")\n",
    "        f.write(f\"{cats_test[group[0]]}\\n\")\n",
    "        for idx in group:\n",
    "            f.write(f\"{file_info_test[idx].title}\\n\\t{file_info_test[idx].text[:800]}\\n\")\n",
    "            \n",
    "        f.write(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25150606036909395"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(*group_comparison(gt_groups, g), average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5474\n",
      "67\n",
      "40\n",
      "\t«Разборки двух партий». Экс-глава МИД Украины заявил об отсутствии «Украиногейта» в США и предложил название «Американогейт»\n",
      "\tТейлор: Джулиани хотел, чтобы Украина вмешалась в американские выборы\n",
      "\tСуд в США обязал обнародовать детали разговора Зеленского и Трампа\n",
      "\tОпрос: Более половины американцев поддерживают импичмент Трампа\n",
      "\tТрамп хотел, чтобы Зеленский сделал заявление о расследовании, Байдене и Клинтон — топ-чиновник Госдепа\n",
      "\tВ Белом доме не увидели доказательств quid pro quo в показаниях топ-дипломатов США\n",
      "\tКонгресс опубликовал показания Волкера и Сондленда в деле об импичменте Трампа\n",
      "\tИмпичмент Трампа: Болтон не пришел на слушания в Конгресс\n",
      "\tТоп-дипломат США признал связь между военной помощью и расследованием против Байдена\n",
      "\tБолее половины американцев поддерживают импичмент Трампа\n",
      "\tВ Конгрессе допустили, что расследование по импичменту «зацепит» не только Украину\n",
      "\t«Мистификация демократов». Трамп заявил, что нет причин анализировать его разговор с Зеленским\n",
      "\tТрамп посоветовал Пелоси очистить улицы от наркотиков вместо траты времени на его импичмент\n",
      "\tИмпичмент Трампа: министр энергетики США отказался давать показания в Конгрессе\n",
      "\tИнформатор в деле об импичменте Трампа согласился дать письменные показания\n",
      "\tС первых дней президентства Трамп ненавидел Украину — WP\n",
      "\tРасследование об импичменте: в Конгресс вызвали руководителя администрации Трампа\n",
      "\tМожет привести к падению. Топ-дипломат США назвал проблемой влияние Коломойского на Зеленского\n",
      "\tВ США назвали вероятное имя информатора, который пожаловался на разговор Трампа и Зеленского\n",
      "\tЗеленский был готов объявить о расследовании против Байдена — NYT\n",
      "\tГосдеп США согласился опубликовать документы, связанные с Украиной и Джулиани\n",
      "\tWP: Трамп требовал от генпрокурора публично заявить, что в его разговоре с Зеленским не было ничего незаконного\n",
      "\tТрамп предложил допросить Байдена в Конгрессе\n",
      "\tГосдеп США по требованию суда согласился опубликовать документы, связанные с Украиной\n",
      "\tВолкер: Джулиани формировал негативное отношение Трампа к Украине\n",
      "\tГосдеп США согласился опубликовать документы, связанные с Украиной\n",
      "\tБелый дом «готов» к возможному импичменту Трампа\n",
      "\tВ обмен на помощь. Трамп хотел, чтобы Зеленский объявил о расследовании против Burisma — топ дипломат\n",
      "\tПосол США в ЕС рассказал о предложении Трампа возобновить помощь Украине в обмен на расследование о сыне Джо Байдена\n",
      "\tТрамп назвал «жульничеством» согласие информатора дать письменные показания в деле об импичменте\n",
      "\tТрамп предложил допросить Байдена в Конгрессе\n",
      "\tТрамп не отправил поздравительное письмо Зеленскому — топ-дипломат США\n",
      "\tБыл озадачен. Волкер рассказал о своем впечатлении от телефонного разговора Трампа и Зеленского\n",
      "\tТрамп ненавидел Украину до встречи с Зеленским - СМИ\n",
      "\tТрамп заявил о желании пригласить Зеленского в США\n",
      "\tКонгресс США назначил первые публичные слушания по импичменту Трампа\n",
      "\tУкраина и США согласовали оборонное сотрудничество\n",
      "\tДаже если Трамп требовал услуги от украинской власти, это не было эффективно — конгрессмен\n",
      "\tБелый дом: В действиях Трампа нет оснований для импичмента\n",
      "\tУкраина и США подписали оборонный протокол\n"
     ]
    }
   ],
   "source": [
    "print(len(g))\n",
    "m = max(len(gg) for gg in g)\n",
    "print(m)\n",
    "g.sort(key=lambda gg: len(gg), reverse=True)\n",
    "gi = 3\n",
    "print(len(g[gi]))\n",
    "for idx2 in g[gi]:\n",
    "    print(\"\\t\" + file_info_test[idx2].title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\" \".join(token for token in news.simple_tokenize_with_numbers(fi.text)) for fi in file_info_test]\n",
    "s = camax_group_idximilarities_within_categories(texts, 3.5, cats_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/graph.tsv\", \"w\") as f:\n",
    "    for idx1, sims in enumerate(s):\n",
    "        for idx2, sim in sims:\n",
    "            f.write(f\"{idx1}\\t{idx2}\\t{sim}\\n\")\n",
    "            f.write(f\"{idx2}\\t{idx1}\\t{sim}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23078"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([i for i, z in enumerate(s) if len(z) != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "relabel = {}\n",
    "with open(\"data/relabel\") as f:\n",
    "    for line in f:\n",
    "        my_lab, other_lab = map(int, line.split(\" \"))\n",
    "        relabel[other_lab] = my_lab\n",
    "\n",
    "last_idx = -1\n",
    "clusters = {}\n",
    "with open(\"data/graph.tree1\") as f:\n",
    "    for line in f:\n",
    "        idx, cluster = map(int, line.split(\" \"))\n",
    "        \n",
    "        if idx < last_idx:\n",
    "            break\n",
    "            \n",
    "        last_idx = idx\n",
    "        if cluster not in clusters:\n",
    "            clusters[cluster] = []\n",
    "            \n",
    "        clusters[cluster].append(relabel[idx])\n",
    "        \n",
    "for c in list(clusters):\n",
    "    if len(clusters[c]) == 1:\n",
    "        del clusters[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "630"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 1\n",
    "cc = list(clusters)\n",
    "for idx2 in clusters[cc[c]]:\n",
    "    print(\"\\t\" + file_info_test[idx2].text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_similarities(similarities, cats):\n",
    "    assert len(similarities) == len(cats), f\"{len(similarities)} != {len(cats)}\"\n",
    "    for i in range(len(similarities)):\n",
    "        if cats[i] == \"junk\":\n",
    "            similarities[i] = []           \n",
    "                        \n",
    "    similarities = [[[idx2, sim] for idx2, sim in sims if cats[idx2] == cats[idx1]] \n",
    "                    for idx1, sims in enumerate(similarities)]\n",
    "    \n",
    "    return similarities\n",
    "\n",
    "def similarity_scores(file_info, cats):\n",
    "    texts = [\" \".join(token for token in news.simple_tokenize_with_numbers(fi.text)) for fi in file_info]\n",
    "    text_sims = postprocess_similarities(calc_similarities(texts), cats)\n",
    "    \n",
    "    titles = [\" \".join(token for token in news.simple_tokenize_with_numbers(fi.title)) for fi in file_info]\n",
    "    title_sims = postprocess_similarities(calc_similarities(titles), cats)\n",
    "        \n",
    "    return text_sims, title_sims\n",
    "\n",
    "text_sims_train, title_sims_train = similarity_scores(file_info_train, cats_train)\n",
    "text_sims_test, title_sims_test = similarity_scores(file_info_test, cats_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.8831964483906771, +510 -1060\n",
      "Title AUC = 0.6188124306326305, +510 -1060\n",
      "Title+text AUC = 0.8916944136145024, +510 -1060\n"
     ]
    }
   ],
   "source": [
    "def similarities_to_tuples(similarities):\n",
    "    similarities_tuples = {}\n",
    "    for idx1, sims in enumerate(similarities):\n",
    "        for idx2, sim in sims:\n",
    "            similarities_tuples[(idx1, idx2)] = sim\n",
    "            similarities_tuples[(idx2, idx1)] = sim\n",
    "            \n",
    "    return similarities_tuples\n",
    "        \n",
    "def similarities_in_gt(similarities_tuples, gt):\n",
    "    gt_similarities = {True: [], False: []}\n",
    "    gt_idx = {True: [], False: []}\n",
    "    for (idx1, idx2), match in manual_ground_truth.items():\n",
    "        gt_similarities[match].append(similarities_tuples[(idx1, idx2)] if (idx1, idx2) in similarities_tuples else 0)\n",
    "        gt_idx[match].append((idx1, idx2))\n",
    "\n",
    "    sims_joined = np.array(gt_similarities[True] + gt_similarities[False])\n",
    "    gt_idx_joined = gt_idx[True] + gt_idx[False]\n",
    "    gt_joined = [1] * len(gt_similarities[True]) + [0] * len(gt_similarities[False])\n",
    "    return sims_joined, gt_joined, gt_idx_joined\n",
    "\n",
    "\n",
    "sims_joined, gt_joined, gt_idx_joined = similarities_in_gt(similarities_to_tuples(text_sims_test), manual_ground_truth)\n",
    "auc = roc_auc_score(gt_joined, sims_joined)\n",
    "print(f\"AUC = {auc}, +{sum(gt_joined)} -{len(gt_joined) - sum(gt_joined)}\")\n",
    "\n",
    "sims_joined_title, _, _ = similarities_in_gt(similarities_to_tuples(title_sims_test), manual_ground_truth)\n",
    "auc = roc_auc_score(gt_joined, sims_joined_title)\n",
    "print(f\"Title AUC = {auc}, +{sum(gt_joined)} -{len(gt_joined) - sum(gt_joined)}\")\n",
    "\n",
    "auc = roc_auc_score(gt_joined, sims_joined_title + sims_joined)\n",
    "print(f\"Title+text AUC = {auc}, +{sum(gt_joined)} -{len(gt_joined) - sum(gt_joined)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title+text AUC = 0.8916944136145024, +510 -1060\n"
     ]
    }
   ],
   "source": [
    "def merge_similarities(sim1, sim2, file_info):\n",
    "    sim1 = similarities_to_tuples(sim1)\n",
    "    sim2 = similarities_to_tuples(sim2)\n",
    "    for ff, sim in sim2.items():\n",
    "        if ff in sim1:\n",
    "            sim1[ff] += sim\n",
    "        else:\n",
    "            sim1[ff] = sim\n",
    "\n",
    "    merged = [{} for _ in range(len(file_info))]\n",
    "    for (idx1, idx2), sim in sim1.items():\n",
    "        merged[idx1][idx2] = sim\n",
    "        merged[idx2][idx1] = sim\n",
    "        \n",
    "    merged = [list(m.items()) for m in merged]    \n",
    "    return merged\n",
    "        \n",
    "similarities_train = merge_similarities(text_sims_train, title_sims_train, file_info_train)\n",
    "similarities_test = merge_similarities(text_sims_test, title_sims_test, file_info_test)\n",
    "\n",
    "sims_joined_both, _, _ = similarities_in_gt(similarities_to_tuples(similarities_test), manual_ground_truth)\n",
    "auc = roc_auc_score(gt_joined, sims_joined_both)\n",
    "print(f\"Title+text AUC = {auc}, +{sum(gt_joined)} -{len(gt_joined) - sum(gt_joined)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5, 15)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data = pd.DataFrame({\"similarity\": sims_joined_both, \"same\": gt_joined, \"idx\": gt_idx_joined})\n",
    "#plot_data = plot_data[(plot_data.similarity < 10) & (plot_data.similarity > -3)]\n",
    "ax = sns.violinplot(x=\"same\", y=\"similarity\", data=plot_data)\n",
    "ax.set_ylim(-5, 15)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "most_similar_unrelated = plot_data[plot_data.same == 0]\n",
    "most_similar_unrelated = most_similar_unrelated.sort_values(\"similarity\", ascending=False)\n",
    "for row in most_similar_unrelated.iloc[20:30, :].itertuples():\n",
    "    print(f\"Similarity: {row.similarity}\")\n",
    "    print(f\"{file_info2[row.idx[0]].file} - {file_info2[row.idx[1]].file}\")\n",
    "    print(f\"\\t{file_info2[row.idx[0]].text}\")\n",
    "    print(f\"\\t{file_info2[row.idx[1]].text}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75760 word stems\n"
     ]
    }
   ],
   "source": [
    "normalizer = news.TextNormalizer(\"russian\")\n",
    "normalizer.train(file_info_train)\n",
    "train_texts_train = normalizer.normalize_texts(file_info_train)\n",
    "train_texts_test = normalizer.normalize_texts(file_info_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = 1\n",
    "max_words = 7000\n",
    "tokenize = keras.preprocessing.text.Tokenizer(num_words=max_words, char_level=False)\n",
    "tokenize.fit_on_texts(train_texts_train)  # fit tokenizer to our training text data\n",
    "x_train = tokenize.texts_to_matrix(train_texts_train).astype(np.float32)\n",
    "x_test = tokenize.texts_to_matrix(train_texts_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_66 (Dense)             (None, 512)               3584000   \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 512)               262144    \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 512)               262144    \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 256)               131072    \n",
      "=================================================================\n",
      "Total params: 4,239,360\n",
      "Trainable params: 4,239,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_37 (InputLayer)           [(None, 7000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_38 (InputLayer)           [(None, 7000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_18 (Sequential)      (None, 256)          4239360     input_37[0][0]                   \n",
      "                                                                 input_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub_18 (TensorFlowO [(None, 256)]        0           sequential_18[1][0]              \n",
      "                                                                 sequential_18[2][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Abs_4 (TensorFlowOp [(None, 256)]        0           tf_op_layer_sub_18[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_18 (TensorFlowO [(None, 1)]          0           tf_op_layer_Abs_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 1)            0           tf_op_layer_Sum_18[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 4,239,360\n",
      "Trainable params: 4,239,360\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "drop_ratio = 0.5\n",
    "embedding_size = 256\n",
    "\n",
    "\n",
    "def bag_embedding(input_shape):\n",
    "    model = models.Sequential()    \n",
    "    #model.add(layers.Dropout(0.4))\n",
    "    model.add(layers.Dense(512, input_shape=input_shape, activation='relu', use_bias=False))#, kernel_regularizer=regularizers.l2(0.0001)))\n",
    "    #model.add(layers.Dropout(drop_ratio))\n",
    "    model.add(layers.Dense(512, activation='relu', use_bias=False))\n",
    "    #model.add(layers.Dropout(drop_ratio))\n",
    "    model.add(layers.Dense(512, activation='relu', use_bias=False))\n",
    "    #model.add(layers.Dropout(drop_ratio))\n",
    "    model.add(layers.Dense(embedding_size, use_bias=False, activation=\"sigmoid\"))\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_siamese_model(emb_model, input_shape):\n",
    "    # Define the tensors for the two input images\n",
    "    left_input = layers.Input(input_shape)\n",
    "    right_input = layers.Input(input_shape)\n",
    "        \n",
    "    # Generate the encodings (feature vectors) for the two images\n",
    "    encoded_l = emb_model(left_input)\n",
    "    encoded_r = emb_model(right_input)\n",
    "    \n",
    "    #emb_diff = K.square(encoded_l - encoded_r)\n",
    "    emb_diff = K.abs(encoded_l - encoded_r)\n",
    "    #emb_diff_drop = layers.Dropout(drop_ratio)(emb_diff)\n",
    "    distance = K.sum(emb_diff, axis=1, keepdims=True)\n",
    "\n",
    "    #prediction1 = layers.Dense(64, activation=\"relu\")(emb_diff)\n",
    "    #prediction = layers.Dense(1, activation=\"sigmoid\")(prediction1)\n",
    "    prediction = layers.Activation('tanh')(distance)\n",
    "    #prediction = distance\n",
    "    \n",
    "    # Connect the inputs with the outputs\n",
    "    siamese_net = models.Model(inputs=[left_input, right_input], outputs=prediction)\n",
    "    \n",
    "    # return the model\n",
    "    return siamese_net\n",
    "\n",
    "emb_model = bag_embedding((max_words,))\n",
    "model = make_siamese_model(emb_model, (max_words,))\n",
    "emb_model.summary()\n",
    "model.summary()\n",
    "\n",
    "optimizer = Adam(lr = 0.0001)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer)\n",
    "#model.compile(loss='mean_squared_error', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_group_train = idx_group(train_groups)\n",
    "idx_group_test = idx_group(test_groups)\n",
    "\n",
    "idx_with_group_train = list(idx_group_train)\n",
    "idx_with_group_test = list(idx_group_test)\n",
    "\n",
    "\n",
    "def get_batch(batch_size, is_train):\n",
    "    \"\"\"Create batch of n pairs, half same class, half different class\"\"\"\n",
    "    x = x_train if is_train else x_test\n",
    "    idx_wg = idx_with_group_train if is_train else idx_with_group_test\n",
    "    idx_g = idx_group_train if is_train else idx_group_test\n",
    "    \n",
    "    n_examples = x.shape[0]\n",
    "   \n",
    "    # initialize vector for the targets\n",
    "    targets = np.zeros((batch_size,))\n",
    "    \n",
    "    # make one half of it '1's, so 2nd half of batch has same class\n",
    "    num_same = batch_size // 2\n",
    "    targets[num_same:] = 1\n",
    "    batch_idx_1 = []\n",
    "    batch_idx_2 = []\n",
    "    for i in range(batch_size):\n",
    "        # pick images of same class for 1st half, different for 2nd\n",
    "        if i < num_same:\n",
    "            idx_1 = idx_wg[rng.randint(0, len(idx_wg))]\n",
    "            ii = rng.randint(0, len(idx_g[idx_1]))\n",
    "            idx_2 = idx_g[idx_1][ii]\n",
    "        else: \n",
    "            idx_1 = rng.randint(0, n_examples)\n",
    "            idx_2 = rng.randint(0, n_examples)\n",
    "            if idx_1 in idx_g:\n",
    "                group = frozenset(idx_g[idx_1])\n",
    "                while True:\n",
    "                    idx_2 = rng.randint(0, n_examples)                    \n",
    "                    if idx_2 not in group:\n",
    "                        break\n",
    "        \n",
    "        batch_idx_1.append(idx_1)\n",
    "        batch_idx_2.append(idx_2)\n",
    "                    \n",
    "    pairs = [x[batch_idx_1, :], x[batch_idx_2, :]]\n",
    "    return pairs, targets\n",
    "\n",
    "def generate(batch_size, is_train):\n",
    "    \"\"\"a generator for batches, so model.fit_generator can be used. \"\"\"\n",
    "    while True:\n",
    "        pairs, targets = get_batch(batch_size, is_train)\n",
    "        yield (pairs, targets)\n",
    "        \n",
    "def embedding_distance(embs, idx1, idx2):\n",
    "    return ((embs[idx1, :] - embs[idx2, :]) ** 2).sum()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training process!\n",
      "-------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25a51137abc449289f1cdd814118db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss before training: 0.5751081615686416\n",
      "Current best loss: 0.4362422139644623, AUC: 0.6578202406227884\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-4eb1b705f177>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mloss_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"train: {loss_sum / (i - last_eval + 0.01):.2g}\\tval: {val_loss:.2g}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[1;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[1;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    266\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backwards\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_total_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m           \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_total_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m           if isinstance(model.optimizer,\n\u001b[1;32m    270\u001b[0m                         loss_scale_optimizer.LossScaleOptimizer):\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MatMulGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1573\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_MatMulGradAgainstFirstOnly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1574\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskip_input_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1575\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_MatMulGradAgainstSecondOnly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1576\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1577\u001b[0m     \u001b[0;31m# No gradient skipping, so do the full gradient computation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MatMulGradAgainstSecondOnly\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1554\u001b[0m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1556\u001b[0;31m     \u001b[0mgrad_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1557\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1558\u001b[0m     \u001b[0mgrad_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   6110\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6111\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_a\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6112\u001b[0;31m         transpose_a, \"transpose_b\", transpose_b)\n\u001b[0m\u001b[1;32m   6113\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6114\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Starting training process!\")\n",
    "print(\"-------------------------------------\")\n",
    "n_iter = 10000\n",
    "eval_samples = 10000\n",
    "batch_size = 32\n",
    "evaluate_every = 1000\n",
    "t = trange(n_iter)\n",
    "loss_sum = 0.0\n",
    "last_eval = 0\n",
    "val_loss = model.evaluate(*get_batch(eval_samples, False), verbose=0)\n",
    "best = val_loss\n",
    "print(f\"val loss before training: {val_loss}\")\n",
    "for i in t:\n",
    "    (inputs,targets) = get_batch(batch_size, True)\n",
    "    loss = model.train_on_batch(inputs, targets)\n",
    "    loss_sum += loss\n",
    "    t.set_description(f\"train: {loss_sum / (i - last_eval + 0.01):.2g}\\tval: {val_loss:.2g}\")\n",
    "    if i % evaluate_every == 0 and i != 0:\n",
    "        loss_sum = 0\n",
    "        last_eval = i\n",
    "        val_loss = model.evaluate(*get_batch(eval_samples, False), verbose=0)\n",
    "#        model.save_weights(os.path.join(model_path, 'weights.{}.h5'.format(i)))\n",
    "        if best > val_loss:\n",
    "            embs_test = emb_model.predict(x_test)\n",
    "            auc = roc_auc_score(*group_to_embedding_comparison(gt_groups, embs_test))\n",
    "            print(f\"Current best loss: {val_loss}, AUC: {auc}\")\n",
    "            best = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data/keras_model_grouping.h5\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Forward pass took 0.016979 s.\n",
      "Forward pass took 0.00348 s.\n",
      "Forward pass took 0.004065 s.\n",
      "Starting performance measurements.\n",
      "Forward pass took 0.003918 s.\n",
      "Forward pass took 0.00412 s.\n",
      "Forward pass took 0.003423 s.\n",
      "Forward pass took 0.003779 s.\n",
      "Forward pass took 0.004162 s.\n",
      "Forward pass took 0.0038804 s on average.\n",
      "Converting model architecture.\n",
      "Converting model weights.\n",
      "Done converting model weights.\n",
      "Calculating model hash.\n",
      "Model conversion finished.\n",
      "writing data/grouping_model_ru.json\n"
     ]
    }
   ],
   "source": [
    "emb_model.save('data/keras_model_grouping.h5', include_optimizer=False)\n",
    "convert_model.convert(\"data/keras_model_grouping.h5\", \"data/grouping_model_ru.json\", no_tests=False)\n",
    "\n",
    "tokenizer_data = json.loads(tokenize.to_json())\n",
    "word_index = json.loads(tokenizer_data[\"config\"][\"word_index\"])\n",
    "with open(\"data/dictionary_for_grouping_ru.tsv\", \"w\") as f:\n",
    "    for word, index in word_index.items():\n",
    "        if index < max_words:\n",
    "            f.write(f\"{word}\\t{index}\\t{normalizer.idf[word] if word in normalizer.idf else 0}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_test = emb_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emb AUC = 0.7345837957824639, +510 -1060\n",
      "weight=1.0 AUC = 0.9189567147613761, +510 -1060\n",
      "weight=8.071428571428571 AUC = 0.9187643359230485, +510 -1060\n",
      "weight=15.142857142857142 AUC = 0.9106178320384757, +510 -1060\n",
      "weight=22.214285714285715 AUC = 0.902286348501665, +510 -1060\n",
      "weight=29.285714285714285 AUC = 0.8929707732149464, +510 -1060\n",
      "weight=36.357142857142854 AUC = 0.8843877173510915, +510 -1060\n",
      "weight=43.42857142857143 AUC = 0.8759378468368479, +510 -1060\n",
      "weight=50.5 AUC = 0.8678061413244543, +510 -1060\n",
      "weight=57.57142857142857 AUC = 0.8602589715131336, +510 -1060\n",
      "weight=64.64285714285714 AUC = 0.8531113577506475, +510 -1060\n",
      "weight=71.71428571428571 AUC = 0.847036625971143, +510 -1060\n",
      "weight=78.78571428571428 AUC = 0.8410432852386238, +510 -1060\n",
      "weight=85.85714285714286 AUC = 0.8358934517203107, +510 -1060\n",
      "weight=92.92857142857143 AUC = 0.8314613392526822, +510 -1060\n",
      "weight=100.0 AUC = 0.8272512023677395, +510 -1060\n",
      "weight=1.0 AUC = 0.9189567147613761, +510 -1060\n",
      "weight=8.071428571428571 AUC = 0.9176766555678876, +510 -1060\n",
      "weight=15.142857142857142 AUC = 0.9175952645209028, +510 -1060\n",
      "weight=22.214285714285715 AUC = 0.9175730669626341, +510 -1060\n",
      "weight=29.285714285714285 AUC = 0.9175508694043655, +510 -1060\n",
      "weight=36.357142857142854 AUC = 0.9175212726600074, +510 -1060\n",
      "weight=43.42857142857143 AUC = 0.9175138734739179, +510 -1060\n",
      "weight=50.5 AUC = 0.9175286718460969, +510 -1060\n",
      "weight=57.57142857142857 AUC = 0.9175286718460969, +510 -1060\n",
      "weight=64.64285714285714 AUC = 0.9175360710321865, +510 -1060\n",
      "weight=71.71428571428571 AUC = 0.9175360710321865, +510 -1060\n",
      "weight=78.78571428571428 AUC = 0.9175360710321865, +510 -1060\n",
      "weight=85.85714285714286 AUC = 0.917528671846097, +510 -1060\n",
      "weight=92.92857142857143 AUC = 0.917528671846097, +510 -1060\n",
      "weight=100.0 AUC = 0.917528671846097, +510 -1060\n",
      "\n",
      "weight=5 AUC = 0.920125786163522, +510 -1060\n"
     ]
    }
   ],
   "source": [
    "gt_similarities = {True: [], False: []}\n",
    "for (idx1, idx2), match in manual_ground_truth.items():\n",
    "    gt_similarities[match].append(-embedding_distance(embs_test, idx1, idx2))\n",
    "\n",
    "sims_joined_nn = np.array(gt_similarities[True] + gt_similarities[False])\n",
    "auc = roc_auc_score(gt_joined, sims_joined_nn)\n",
    "print(f\"Emb AUC = {auc}, +{len(gt_similarities[True])} -{len(gt_similarities[False])}\")\n",
    "\n",
    "for weight in np.linspace(1, 100, 15):\n",
    "    auc = roc_auc_score(gt_joined, sims_joined_both + sims_joined_nn * weight)\n",
    "    print(f\"weight={weight} AUC = {auc}, +{len(gt_similarities[True])} -{len(gt_similarities[False])}\")\n",
    "\n",
    "for weight in np.linspace(1, 100, 15):\n",
    "    auc = roc_auc_score(gt_joined, sims_joined_both * weight + sims_joined_nn)\n",
    "    print(f\"weight={weight} AUC = {auc}, +{len(gt_similarities[True])} -{len(gt_similarities[False])}\")    \n",
    "    \n",
    "print()\n",
    "weight = 5\n",
    "auc = roc_auc_score(gt_joined, sims_joined_both + sims_joined_nn * weight)\n",
    "print(f\"weight={weight} AUC = {auc}, +{len(gt_similarities[True])} -{len(gt_similarities[False])}\")\n",
    "\n",
    "#f1 = f1_score(gt_joined, sims_joined_both + sims_joined_2 * weight)\n",
    "#print(f\"weight={weight} F1 = {f1}, +{len(gt_similarities[True])} -{len(gt_similarities[False])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-10, 20)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data = pd.DataFrame({\"score\": sims_joined_both + sims_joined_nn * weight, \"same\": gt_joined, \"idx\": gt_idx_joined})\n",
    "ax = sns.violinplot(x=\"same\", y=\"score\", data=plot_data)\n",
    "ax.set_ylim(-10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter = umap.UMAP(n_components=5)\n",
    "embs2_umap = fitter.fit_transform(embs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embs2 UMAP AUC = 0.732032972520339, +494 -1054\n",
      "similarity AUC = 0.890469312970062, +494 -1054\n",
      "weight=1.0 AUC = 0.8990158947214775, +494 -1054\n",
      "weight=8.071428571428571 AUC = 0.9130514945954875, +494 -1054\n",
      "weight=15.142857142857142 AUC = 0.9125214144688827, +494 -1054\n",
      "weight=22.214285714285715 AUC = 0.9119145111355239, +494 -1054\n",
      "weight=29.285714285714285 AUC = 0.911952922738901, +494 -1054\n",
      "weight=36.357142857142854 AUC = 0.9116225829498577, +494 -1054\n",
      "weight=43.42857142857143 AUC = 0.9115611243844541, +494 -1054\n",
      "weight=50.5 AUC = 0.9115918536671559, +494 -1054\n",
      "weight=57.57142857142857 AUC = 0.9115764890258049, +494 -1054\n",
      "weight=64.64285714285714 AUC = 0.9115688067051295, +494 -1054\n",
      "weight=71.71428571428571 AUC = 0.911507348139726, +494 -1054\n",
      "weight=78.78571428571428 AUC = 0.9114766188570244, +494 -1054\n",
      "weight=85.85714285714286 AUC = 0.9114919834983752, +494 -1054\n",
      "weight=92.92857142857143 AUC = 0.9114612542156735, +494 -1054\n",
      "weight=100.0 AUC = 0.9114228426122964, +494 -1054\n"
     ]
    }
   ],
   "source": [
    "file_to_idx = {fi.file: i for i, fi in enumerate(file_info2)}\n",
    "\n",
    "gt_similarities = {True: [], False: []}\n",
    "for (idx1, idx2), match in manual_ground_truth.items():\n",
    "    gt_similarities[match].append(-((embs2_umap[file_to_idx[idx1], :] - embs2_umap[file_to_idx[idx2]]) ** 2).sum())\n",
    "\n",
    "sims_joined_3 = np.array(gt_similarities[True] + gt_similarities[False])\n",
    "auc = roc_auc_score([1] * len(gt_similarities[True]) + [0] * len(gt_similarities[False]), sims_joined_3)\n",
    "print(f\"embs2 UMAP AUC = {auc}, +{len(gt_similarities[True])} -{len(gt_similarities[False])}\")\n",
    "\n",
    "auc = roc_auc_score([1] * len(gt_similarities[True]) + [0] * len(gt_similarities[False]), sims_joined)\n",
    "print(f\"similarity AUC = {auc}, +{len(gt_similarities[True])} -{len(gt_similarities[False])}\")\n",
    "\n",
    "for weight in np.linspace(1, 100, 15):\n",
    "    auc = roc_auc_score([1] * len(gt_similarities[True]) + [0] * len(gt_similarities[False]), sims_joined * weight + sims_joined_3)\n",
    "    print(f\"weight={weight} AUC = {auc}, +{len(gt_similarities[True])} -{len(gt_similarities[False])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_coefs_test = news.run_nn(file_info_test, \"russian\", news.category_model_ru, news.dictionary_ru)\n",
    "category_coefs_test = np.array(category_coefs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat-emb AUC = 0.4928375878653348, +510 -1060\n"
     ]
    }
   ],
   "source": [
    "gt_similarities = {True: [], False: []}\n",
    "for (idx1, idx2), match in manual_ground_truth.items():\n",
    "    gt_similarities[match].append(-embedding_distance(category_coefs_test, idx1, idx2))\n",
    "\n",
    "sims_joined_catnn = np.array(gt_similarities[True] + gt_similarities[False])\n",
    "auc = roc_auc_score(gt_joined, sims_joined_catnn)\n",
    "print(f\"cat-emb AUC = {auc}, +{len(gt_similarities[True])} -{len(gt_similarities[False])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/manual_grouping.txt\", \"w\") as f:\n",
    "    for idx1 in np.random.choice(len(similarities2), 1000):\n",
    "        cat = cats2[file_info2[idx1].file]\n",
    "        if cat == \"junk\":\n",
    "            continue\n",
    "            \n",
    "        f.write(f\"\\n\\n\\nFILE#{idx1}\\n{cat}\\n{file_info2[idx1].text}\\n\")\n",
    "        sims = similarities2[idx1]\n",
    "        sims_adjusted = [(idx2, sim - 5 * embedding_distance(embs2, idx1, idx2)) for idx2, sim in sims]\n",
    "        sims_adjusted.sort(key=lambda x: x[1], reverse=True)\n",
    "        for idx2, similarity in sims_adjusted:\n",
    "            assignment = \"\"\n",
    "            if (file_info2[idx1].file, file_info2[idx2].file) in manual_ground_truth:\n",
    "                assignment = \"+\" if manual_ground_truth[file_info2[idx1].file, file_info2[idx2].file] else \"-\"\n",
    "                \n",
    "            cat2 = cats2[file_info2[idx2].file]\n",
    "            f.write(f\"\\nSimilarity = {similarity}\\n{cat2}\\n\\t{file_info2[idx2].text[:800]}\\nOTHER#{idx2}:\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877 GT examples loaded\n",
      "1053 examples now in GT\n"
     ]
    }
   ],
   "source": [
    "manual_ground_truth = {}\n",
    "if os.path.exists(os.path.join(folder2, \"gt_groups\")):\n",
    "    with open(os.path.join(folder2, \"gt_groups\")) as f:\n",
    "        for line in f:\n",
    "            idx1, idx2, match = line.strip().split(\"\\t\")\n",
    "            match = match == \"True\"\n",
    "            manual_ground_truth[(idx1, idx2)] = match\n",
    "            manual_ground_truth[(idx2, idx1)] = match\n",
    "        \n",
    "print(len(manual_ground_truth) // 2, \"GT examples loaded\")\n",
    "\n",
    "with open(\"data/manual_grouping.txt\") as f:\n",
    "    idx1 = None\n",
    "    for line in f:\n",
    "        if line.startswith(\"FILE#\"):\n",
    "            idx1 = file_info2[int(line.split(\"#\")[1].strip())].file\n",
    "        elif line.startswith(\"OTHER#\"):\n",
    "            idx2 = file_info2[int(line.split(\"#\")[1].split(\":\")[0])].file\n",
    "            mark = line.split(\":\")[1].strip()\n",
    "            if mark == \"\":\n",
    "                continue\n",
    "            \n",
    "            match = mark[0] != \"-\"\n",
    "            manual_ground_truth[(idx1, idx2)] = match\n",
    "            manual_ground_truth[(idx2, idx1)] = match\n",
    "    \n",
    "print(len(manual_ground_truth) // 2, \"examples now in GT\")\n",
    "\n",
    "with open(os.path.join(folder2, \"gt_groups\"), \"w\") as f:\n",
    "    for (idx1, idx2), match in manual_ground_truth.items():\n",
    "        f.write(f\"{idx1}\\t{idx2}\\t{match}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
